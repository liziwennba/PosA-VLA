<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention">
  <meta name="keywords" content="Robotics, VLA, Manipulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention</title>

  <!-- 引入 Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- 引入 CSS 框架 (Bulma) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">

  <style>
    body { font-family: 'Noto Sans', sans-serif; }
    .title.is-1 { font-family: 'Google Sans', sans-serif; font-weight: 700; }
    .publication-title { font-size: 2.5rem; }
    .publication-authors { font-size: 1.25rem; margin-top: 20px; }
    .publication-links { margin-top: 30px; }
    .button.is-dark { background-color: #363636; border-color: transparent; color: #fff; }
    .hero-body { padding: 3rem 1.5rem; }
    
    /* 视频容器样式 */
    .video-container {
      position: relative;
      width: 100%;
      border-radius: 10px;
      overflow: hidden;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      margin-bottom: 10px;
    }
    video { width: 100%; display: block; }
    
    /* 分类标题样式 */
    .category-title {
      border-bottom: 2px solid #f5f5f5;
      padding-bottom: 10px;
      margin-top: 40px;
      margin-bottom: 20px;
      color: #363636;
    }
    
    .caption {
      font-size: 0.95em;
      color: #4a4a4a;
      margin-top: 5px;
      text-align: center;
      font-weight: 500;
    }
    
    /* 调整列间距 */
    .columns.is-multiline {
      margin-bottom: 0;
    }
  </style>
</head>
<body>

<!-- 头部：标题、作者、链接 -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">Ziwen Li<sup>1</sup>,</span>
            <span class="author-block">Xin Wang<sup>2</sup>,</span>
            <span class="author-block">Hanlue Zhang<sup>1</sup>,</span>
            <span class="author-block">Runnan Chen<sup>3</sup>,</span>
            <span class="author-block">Runqi Lin<sup>3</sup>,</span>
            <span class="author-block">Xiao He<sup>2</sup>,</span>
            <span class="author-block">Han Huang<sup>2</sup>,</span>
            <span class="author-block">Yandong Guo<sup>2</sup>,</span>
            <span class="author-block">Fakhri Karray<sup>1</sup>,</span>
            <span class="author-block">Tongliang Liu<sup>1,3</sup>,</span>
            <span class="author-block">Mingming Gong<sup>1,4</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>MBZUAI,</span>
            <span class="author-block"><sup>2</sup>AI2Robotics,</span>
            <span class="author-block"><sup>3</sup>The University of Sydney,</span>
            <span class="author-block"><sup>4</sup>The University of Melbourne</span>
          </div>

          <!-- 链接按钮 -->
          <div class="publication-links">
            <span class="link-block">
              <a href="https://arxiv.org/abs/2512.03724" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper (arXiv)</span>
              </a>
            </span>
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code (Coming Soon)</span>
              </a>
            </span>
            <span class="link-block">
              <a href="#demo-videos" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-youtube"></i></span>
                <span>Demo Videos</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Abstract (已移除视频) -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The Vision-Language-Action (VLA) models have demonstrated remarkable performance on embodied tasks and
            shown promising potential for real-world applications.
            However, current VLAs fail to exhibit consistent and precise target-oriented actions, as they often generate redundant motions along trajectories, limiting their applicability in time-sensitive scenarios. In this work, we attribute
            the redundant actions to the spatially uniform perception
            field of VLAs, which leads them to be distracted by target-
            irrelevant objects, particularly in complex environments. To
            this end, we propose an efficient PosA-VLA framework,
            which anchors visual attention via pose-conditioned supervision, consistently guiding the model's perception toward
            task-relevant regions. The pose-conditioned anchor attention mechanism enables the model to better align instruc-
            tion semantics with actionable visual cues, thereby enhancing action generation precision and efficiency. Moreover,
            our framework is built upon a lightweight architecture and
            requires no auxiliary perception modules (e.g., segmentation or grounding networks), ensuring efficient inference.
            Extensive experiments verify that our method performs embodied tasks with precise and time-efficient execution across
            diverse robotic manipulation benchmarks and shows robust
            generalization in various environments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Methodology -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Methodology</h2>
        <img src="./static/images/framework.png" alt="Architecture" style="width:100%; border-radius:10px;">
        <div class="content has-text-justified">
          <p>
            Overview of the PosA-VLA architecture. A CLIP text encoder extracts the textual feature, while a CLIP image
            encoder produces patch-wise visual features from head and wrist cameras. These features are fused through a cross-attention module
            to generate anchor attention weights, which are supervised by the proposed anchor loss using the ground-truth pose-conditioned anchor
            maps. The anchor attention weights are then applied to DINOv2 image features via element-wise multiplication to obtain refined visual
            representations. Finally, the refined visual features, together with the text feature and the robot state feature, are fed into the Flow Matching
            Transformer (FMT) to predict the continuous action sequence.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 视频展示区 -->
<section class="section" id="demo-videos">
  <div class="container is-max-desktop">
    
    <!-- 分类 1: Robustness & Generalization -->
    <h2 class="title is-3 category-title">1. Robustness & Generalization Tests</h2>
    <div class="columns is-multiline is-centered">
      <!-- 视频 1.1: Basic Tissue -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/basic_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Basic: Pick up tissue</p>
      </div>

      <!-- 视频 1.2: Unseen Background Bottle -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/background_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Unseen Background: Pick up bottle</p>
      </div>

      <!-- 视频 1.3: Unseen Light Banana -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/light_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Unseen Light: Pick up banana</p>
      </div>

      <!-- 视频 1.4: Distractor Bread -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/distractor_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Distractor: Pick up bread</p>
      </div>

      <!-- 视频 1.5: Unseen Object Carrot -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/unseen_object_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Unseen Object: Pick up carrot</p>
      </div>

      <!-- 视频 1.6: Attention Vis Bottle -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/pick_up_the_water_bottle_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Pick up bottle (Attention Vis)</p>
      </div>
    </div>


    <!-- 分类 2: Spatial Reasoning & Instruction Following -->
    <h2 class="title is-3 category-title">2. Spatial Reasoning & Instruction Following</h2>
    <div class="columns is-multiline is-centered">
      
      <!-- 视频 2.1: Bread Left -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/pick_up_the_bread_and_place_it_on_the_left_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Put bread to the left</p>
      </div>

      <!-- 视频 2.2: Bread Right -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/pick_up_the_bread_and_place_it_on_the_right_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Put bread to the right</p>
      </div>

      <!-- 视频 2.3: Bread Top (Attn) -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/pick_up_the_bread_and_place_it_on_the_top_attention_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Put bread to the top (Attention Vis)</p>
      </div>

      <!-- 视频 2.4: Carrot Bottom -> Plate Left -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/carrot_down_left_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Carrot (bottom) &rarr; Plate Left</p>
      </div>

      <!-- 视频 2.5: Carrot Top -> Plate Right -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/carrot_up_right_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Carrot (top) &rarr; Plate Right</p>
      </div>

      <!-- 视频 2.6: Carrot Bottom -> Plate Right (Attn) -->
      <div class="column is-one-third">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/Pick_up_the_carrot_by_the_bottom_end_and_place_it_on_the_right_side_of_the_plate_cut.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Carrot (bottom) &rarr; Plate Right (Attn Vis)</p>
      </div>
    </div>


    <!-- 分类 3: Long-Horizon Tasks & Benchmark -->
    <h2 class="title is-3 category-title">3. Long-Horizon Task & Benchmark Visualization</h2>
    <div class="columns is-centered">
      
      <!-- 视频 3.1: Long Task Towel -->
      <div class="column is-half">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/long_compressed.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">Long-Horizon: Put towel into the box</p>
      </div>

      <!-- 视频 3.2: Libero Visualization -->
      <div class="column is-half">
        <div class="video-container">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/pick_up_the_black_bowl_in_the_top_drawer_of_the_wooden_cabinet_and_place_it_on_the_plate_cut.mp4" type="video/mp4">
          </video>
        </div>
        <p class="caption">LIBERO Benchmark Visualization</p>
      </div>
    </div>

  </div>
</section>

<!-- BibTeX 引用 -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{li2025posa,
  author    = {Ziwen Li, Xin Wang, Hanlue Zhang, Runnan Chen, Runqi Lin, Xiao He, Han Huang, Yandong Guo, Fakhri Karray, Tongliang Liu, Mingming Gong},
  title     = {PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention},
  journal   = {arXiv preprint arXiv:2512.03724},
  year      = {2025},
  url       = {https://arxiv.org/abs/2512.03724},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>